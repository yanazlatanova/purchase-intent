{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eac36ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Administrative</th><th>Administrative_Duration</th><th>Informational</th><th>Informational_Duration</th><th>ProductRelated</th><th>ProductRelated_Duration</th><th>BounceRates</th><th>ExitRates</th><th>PageValues</th><th>SpecialDay</th><th>Month</th><th>OperatingSystems</th><th>Browser</th><th>Region</th><th>TrafficType</th><th>VisitorType</th><th>Weekend</th><th>Revenue</th></tr>\n",
       "<tr><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>22</td><td>370.3333333</td><td>0.018181818</td><td>0.054545455</td><td>0.0</td><td>0.6</td><td>May</td><td>2</td><td>2</td><td>4</td><td>13</td><td>Returning_Visitor</td><td>false</td><td>false</td></tr>\n",
       "<tr><td>12</td><td>381.5</td><td>1</td><td>22.2</td><td>154</td><td>7835.874629</td><td>0.012549679</td><td>0.022587818</td><td>0.0</td><td>0.0</td><td>Aug</td><td>3</td><td>2</td><td>1</td><td>2</td><td>Returning_Visitor</td><td>true</td><td>false</td></tr>\n",
       "<tr><td>5</td><td>44.75</td><td>3</td><td>51.5</td><td>107</td><td>3074.852778</td><td>0.015454545</td><td>0.026239965</td><td>0.0</td><td>0.0</td><td>Nov</td><td>2</td><td>2</td><td>3</td><td>1</td><td>Returning_Visitor</td><td>true</td><td>false</td></tr>\n",
       "<tr><td>1</td><td>12.0</td><td>0</td><td>0.0</td><td>11</td><td>213.0</td><td>0.05</td><td>0.066666667</td><td>0.0</td><td>0.0</td><td>Nov</td><td>2</td><td>2</td><td>4</td><td>13</td><td>Returning_Visitor</td><td>true</td><td>false</td></tr>\n",
       "<tr><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>1</td><td>0.0</td><td>0.2</td><td>0.2</td><td>0.0</td><td>0.0</td><td>May</td><td>1</td><td>1</td><td>3</td><td>3</td><td>New_Visitor</td><td>false</td><td>false</td></tr>\n",
       "<tr><td>1</td><td>18.0</td><td>1</td><td>16.0</td><td>33</td><td>504.0</td><td>0.006060606</td><td>0.033333333</td><td>0.0</td><td>0.0</td><td>May</td><td>2</td><td>4</td><td>1</td><td>4</td><td>Returning_Visitor</td><td>false</td><td>false</td></tr>\n",
       "<tr><td>1</td><td>51.4</td><td>0</td><td>0.0</td><td>7</td><td>562.3</td><td>0.0</td><td>0.0</td><td>36.65735004</td><td>0.0</td><td>Jul</td><td>1</td><td>1</td><td>6</td><td>2</td><td>New_Visitor</td><td>true</td><td>true</td></tr>\n",
       "<tr><td>2</td><td>46.4</td><td>0</td><td>0.0</td><td>8</td><td>349.0</td><td>0.02</td><td>0.08</td><td>0.0</td><td>0.0</td><td>Aug</td><td>4</td><td>1</td><td>1</td><td>1</td><td>Returning_Visitor</td><td>false</td><td>false</td></tr>\n",
       "<tr><td>4</td><td>54.4</td><td>0</td><td>0.0</td><td>68</td><td>2889.946154</td><td>0.002898551</td><td>0.008789401</td><td>0.0</td><td>0.0</td><td>June</td><td>4</td><td>1</td><td>4</td><td>1</td><td>Returning_Visitor</td><td>false</td><td>false</td></tr>\n",
       "<tr><td>3</td><td>335.5</td><td>1</td><td>15.0</td><td>4</td><td>96.0</td><td>0.0</td><td>0.025</td><td>0.0</td><td>0.0</td><td>Nov</td><td>1</td><td>1</td><td>8</td><td>15</td><td>Returning_Visitor</td><td>false</td><td>false</td></tr>\n",
       "<tr><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>2</td><td>36.5</td><td>0.0</td><td>0.033333333</td><td>0.0</td><td>0.0</td><td>Mar</td><td>3</td><td>2</td><td>1</td><td>1</td><td>Returning_Visitor</td><td>false</td><td>false</td></tr>\n",
       "<tr><td>8</td><td>160.5</td><td>2</td><td>1467.0</td><td>26</td><td>721.0</td><td>0.0</td><td>0.031029186</td><td>0.0</td><td>0.0</td><td>Mar</td><td>2</td><td>2</td><td>1</td><td>1</td><td>Returning_Visitor</td><td>false</td><td>false</td></tr>\n",
       "<tr><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>7</td><td>87.5</td><td>0.028571429</td><td>0.085714286</td><td>0.0</td><td>0.6</td><td>May</td><td>2</td><td>2</td><td>4</td><td>2</td><td>Returning_Visitor</td><td>false</td><td>false</td></tr>\n",
       "<tr><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>1</td><td>0.0</td><td>0.2</td><td>0.2</td><td>0.0</td><td>0.0</td><td>Feb</td><td>1</td><td>1</td><td>3</td><td>3</td><td>Returning_Visitor</td><td>false</td><td>false</td></tr>\n",
       "<tr><td>16</td><td>381.6731217</td><td>3</td><td>199.4</td><td>86</td><td>1618.40328</td><td>0.015067698</td><td>0.022043153</td><td>3.885233567</td><td>0.0</td><td>Jul</td><td>3</td><td>2</td><td>8</td><td>4</td><td>Returning_Visitor</td><td>false</td><td>true</td></tr>\n",
       "<tr><td>4</td><td>26.0</td><td>0</td><td>0.0</td><td>18</td><td>727.6190476</td><td>0.0</td><td>0.013333333</td><td>0.0</td><td>0.0</td><td>May</td><td>2</td><td>2</td><td>5</td><td>3</td><td>New_Visitor</td><td>true</td><td>false</td></tr>\n",
       "<tr><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>2</td><td>54.5</td><td>0.1</td><td>0.12</td><td>0.0</td><td>0.0</td><td>May</td><td>3</td><td>2</td><td>1</td><td>6</td><td>Returning_Visitor</td><td>false</td><td>false</td></tr>\n",
       "<tr><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>65</td><td>6053.466667</td><td>0.005208333</td><td>0.026197917</td><td>0.0</td><td>0.0</td><td>Sep</td><td>2</td><td>4</td><td>9</td><td>3</td><td>Returning_Visitor</td><td>false</td><td>false</td></tr>\n",
       "<tr><td>11</td><td>196.15</td><td>0</td><td>0.0</td><td>141</td><td>2623.580864</td><td>0.0</td><td>0.004244028</td><td>12.50786523</td><td>0.0</td><td>Nov</td><td>2</td><td>2</td><td>6</td><td>2</td><td>Returning_Visitor</td><td>false</td><td>false</td></tr>\n",
       "<tr><td>5</td><td>105.5</td><td>0</td><td>0.0</td><td>16</td><td>733.252381</td><td>0.0</td><td>0.006862745</td><td>0.0</td><td>0.0</td><td>May</td><td>3</td><td>2</td><td>1</td><td>6</td><td>New_Visitor</td><td>false</td><td>false</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------------+-----------------------+-------------+----------------------+--------------+-----------------------+-----------+-----------+-----------+----------+-----+----------------+-------+------+-----------+-----------------+-------+-------+\n",
       "|Administrative|Administrative_Duration|Informational|Informational_Duration|ProductRelated|ProductRelated_Duration|BounceRates|  ExitRates| PageValues|SpecialDay|Month|OperatingSystems|Browser|Region|TrafficType|      VisitorType|Weekend|Revenue|\n",
       "+--------------+-----------------------+-------------+----------------------+--------------+-----------------------+-----------+-----------+-----------+----------+-----+----------------+-------+------+-----------+-----------------+-------+-------+\n",
       "|             0|                    0.0|            0|                   0.0|            22|            370.3333333|0.018181818|0.054545455|        0.0|       0.6|  May|               2|      2|     4|         13|Returning_Visitor|  false|  false|\n",
       "|            12|                  381.5|            1|                  22.2|           154|            7835.874629|0.012549679|0.022587818|        0.0|       0.0|  Aug|               3|      2|     1|          2|Returning_Visitor|   true|  false|\n",
       "|             5|                  44.75|            3|                  51.5|           107|            3074.852778|0.015454545|0.026239965|        0.0|       0.0|  Nov|               2|      2|     3|          1|Returning_Visitor|   true|  false|\n",
       "|             1|                   12.0|            0|                   0.0|            11|                  213.0|       0.05|0.066666667|        0.0|       0.0|  Nov|               2|      2|     4|         13|Returning_Visitor|   true|  false|\n",
       "|             0|                    0.0|            0|                   0.0|             1|                    0.0|        0.2|        0.2|        0.0|       0.0|  May|               1|      1|     3|          3|      New_Visitor|  false|  false|\n",
       "|             1|                   18.0|            1|                  16.0|            33|                  504.0|0.006060606|0.033333333|        0.0|       0.0|  May|               2|      4|     1|          4|Returning_Visitor|  false|  false|\n",
       "|             1|                   51.4|            0|                   0.0|             7|                  562.3|        0.0|        0.0|36.65735004|       0.0|  Jul|               1|      1|     6|          2|      New_Visitor|   true|   true|\n",
       "|             2|                   46.4|            0|                   0.0|             8|                  349.0|       0.02|       0.08|        0.0|       0.0|  Aug|               4|      1|     1|          1|Returning_Visitor|  false|  false|\n",
       "|             4|                   54.4|            0|                   0.0|            68|            2889.946154|0.002898551|0.008789401|        0.0|       0.0| June|               4|      1|     4|          1|Returning_Visitor|  false|  false|\n",
       "|             3|                  335.5|            1|                  15.0|             4|                   96.0|        0.0|      0.025|        0.0|       0.0|  Nov|               1|      1|     8|         15|Returning_Visitor|  false|  false|\n",
       "|             0|                    0.0|            0|                   0.0|             2|                   36.5|        0.0|0.033333333|        0.0|       0.0|  Mar|               3|      2|     1|          1|Returning_Visitor|  false|  false|\n",
       "|             8|                  160.5|            2|                1467.0|            26|                  721.0|        0.0|0.031029186|        0.0|       0.0|  Mar|               2|      2|     1|          1|Returning_Visitor|  false|  false|\n",
       "|             0|                    0.0|            0|                   0.0|             7|                   87.5|0.028571429|0.085714286|        0.0|       0.6|  May|               2|      2|     4|          2|Returning_Visitor|  false|  false|\n",
       "|             0|                    0.0|            0|                   0.0|             1|                    0.0|        0.2|        0.2|        0.0|       0.0|  Feb|               1|      1|     3|          3|Returning_Visitor|  false|  false|\n",
       "|            16|            381.6731217|            3|                 199.4|            86|             1618.40328|0.015067698|0.022043153|3.885233567|       0.0|  Jul|               3|      2|     8|          4|Returning_Visitor|  false|   true|\n",
       "|             4|                   26.0|            0|                   0.0|            18|            727.6190476|        0.0|0.013333333|        0.0|       0.0|  May|               2|      2|     5|          3|      New_Visitor|   true|  false|\n",
       "|             0|                    0.0|            0|                   0.0|             2|                   54.5|        0.1|       0.12|        0.0|       0.0|  May|               3|      2|     1|          6|Returning_Visitor|  false|  false|\n",
       "|             0|                    0.0|            0|                   0.0|            65|            6053.466667|0.005208333|0.026197917|        0.0|       0.0|  Sep|               2|      4|     9|          3|Returning_Visitor|  false|  false|\n",
       "|            11|                 196.15|            0|                   0.0|           141|            2623.580864|        0.0|0.004244028|12.50786523|       0.0|  Nov|               2|      2|     6|          2|Returning_Visitor|  false|  false|\n",
       "|             5|                  105.5|            0|                   0.0|            16|             733.252381|        0.0|0.006862745|        0.0|       0.0|  May|               3|      2|     1|          6|      New_Visitor|  false|  false|\n",
       "+--------------+-----------------------+-------------+----------------------+--------------+-----------------------+-----------+-----------+-----------+----------+-----+----------------+-------+------+-----------+-----------------+-------+-------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"PurchaseIntentionAnalysis\")\n",
    "    .remote(\"sc://192.168.1.7:15002\")\n",
    "    .config(\"spark.sql.ansi.enabled\", \"false\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", \"true\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "sessions_data = spark.read.csv([\"/opt/spark/data/worker1/*.csv\", \"/opt/spark/data/worker2/*.csv\"], header=True, inferSchema=True)\n",
    "sessions_data.createOrReplaceTempView(\"sessions_data\")\n",
    "sessions_data.repartition(3)\n",
    "\n",
    "sessions_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07874f89",
   "metadata": {},
   "outputs": [
    {
     "ename": "SparkException",
     "evalue": "[FAILED_READ_FILE.FILE_NOT_EXIST] Encountered error while reading file file:///opt/spark/data/worker2/online_shoppers_part2.csv. File does not exist. It is possible the underlying files have been updated.\nYou can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved. SQLSTATE: KD001\n\nJVM stacktrace:\norg.apache.spark.SparkException\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.fileNotExistError(QueryExecutionErrors.scala:831)\n\tat org.apache.spark.sql.execution.datasources.v2.FileDataSourceV2$.attachFilePath(FileDataSourceV2.scala:140)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:142)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(:-1)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:263)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:265)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.api.python.PythonRDD$.writeNextElementToStream(PythonRDD.scala:333)\n\tat org.apache.spark.sql.execution.python.BasePythonUDFRunner$$anon$1.writeNextInputToStream(PythonUDFRunner.scala:69)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.writeAdditionalInputToPythonWorker(PythonRunner.scala:844)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.read(PythonRunner.scala:767)\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:244)\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:263)\n\tat java.io.DataInputStream.readInt(DataInputStream.java:381)\n\tat org.apache.spark.sql.execution.python.BasePythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:98)\n\tat org.apache.spark.sql.execution.python.BasePythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:90)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:601)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(:-1)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.lang.Thread.run(Thread.java:840)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:544)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:497)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:58)\n\tat org.apache.spark.sql.classic.Dataset.collectFromPlan(Dataset.scala:2244)\n\tat org.apache.spark.sql.classic.Dataset.$anonfun$head$1(Dataset.scala:1379)\n\tat org.apache.spark.sql.classic.Dataset.$anonfun$withAction$2(Dataset.scala:2234)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)\n\tat org.apache.spark.sql.classic.Dataset.$anonfun$withAction$1(Dataset.scala:2232)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$8(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:272)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$7(SQLExecution.scala:125)\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:186)\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:295)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:124)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:237)\n\tat org.apache.spark.sql.classic.Dataset.withAction(Dataset.scala:2232)\n\tat org.apache.spark.sql.classic.Dataset.head(Dataset.scala:1379)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2810)\n\tat org.apache.spark.sql.classic.Dataset.getRows(Dataset.scala:339)\n\tat org.apache.spark.sql.classic.Dataset.showString(Dataset.scala:375)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.transformShowString(SparkConnectPlanner.scala:307)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.$anonfun$transformRelation$1(SparkConnectPlanner.scala:150)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$usePlanCache$3(SessionHolder.scala:477)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.connect.service.SessionHolder.usePlanCache(SessionHolder.scala:476)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.transformRelation(SparkConnectPlanner.scala:147)\n\tat org.apache.spark.sql.connect.execution.SparkConnectPlanExecution.handlePlan(SparkConnectPlanExecution.scala:74)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.handlePlan(ExecuteThreadRunner.scala:314)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:225)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:196)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:341)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:341)\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:186)\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:340)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:196)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:125)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:347)\nCaused by: java.io.FileNotFoundException: File file:/opt/spark/data/worker2/online_shoppers_part2.csv does not exist\n\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:917)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1238)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:907)\n\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)\n\tat org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:189)\n\tat org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:572)\n\tat org.apache.hadoop.fs.ChecksumFileSystem.lambda$openFileWithOptions$0(ChecksumFileSystem.java:1100)\n\tat org.apache.hadoop.util.LambdaUtils.eval(LambdaUtils.java:52)\n\tat org.apache.hadoop.fs.ChecksumFileSystem.openFileWithOptions(ChecksumFileSystem.java:1098)\n\tat org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder.build(FileSystem.java:4952)\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:100)\n\tat org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.$anonfun$_iterator$2(HadoopFileLinesReader.scala:66)\n\tat org.apache.spark.util.SparkErrorUtils.tryInitializeResource(SparkErrorUtils.scala:59)\n\tat org.apache.spark.util.SparkErrorUtils.tryInitializeResource$(SparkErrorUtils.scala:56)\n\tat org.apache.spark.util.Utils$.tryInitializeResource(Utils.scala:99)\n\tat org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.<init>(HadoopFileLinesReader.scala:65)\n\tat org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$.$anonfun$readFile$1(CSVDataSource.scala:105)\n\tat org.apache.spark.TaskContextImpl.createResourceUninterruptibly(TaskContextImpl.scala:332)\n\tat org.apache.spark.util.Utils$.$anonfun$createResourceUninterruptiblyIfInTaskThread$1(Utils.scala:3097)\n\tat scala.Option.map(Option.scala:242)\n\tat org.apache.spark.util.Utils$.createResourceUninterruptiblyIfInTaskThread(Utils.scala:3096)\n\tat org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$.readFile(CSVDataSource.scala:105)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.$anonfun$buildReader$2(CSVFileFormat.scala:147)\n\tat org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.apply(FileFormat.scala:155)\n\tat org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.apply(FileFormat.scala:140)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:230)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:289)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext0(FileScanRDD.scala:131)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:140)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(:-1)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:263)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:265)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.api.python.PythonRDD$.writeNextElementToStream(PythonRDD.scala:333)\n\tat org.apache.spark.sql.execution.python.BasePythonUDFRunner$$anon$1.writeNextInputToStream(PythonUDFRunner.scala:69)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.writeAdditionalInputToPythonWorker(PythonRunner.scala:844)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.read(PythonRunner.scala:767)\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:244)\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:263)\n\tat java.io.DataInputStream.readInt(DataInputStream.java:381)\n\tat org.apache.spark.sql.execution.python.BasePythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:98)\n\tat org.apache.spark.sql.execution.python.BasePythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:90)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:601)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(:-1)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.lang.Thread.run(Thread.java:840)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSparkException\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\plancha\\purchase-intent\\.venv\\lib\\site-packages\\IPython\\core\\formatters.py:770\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    763\u001b[0m stream \u001b[38;5;241m=\u001b[39m StringIO()\n\u001b[0;32m    764\u001b[0m printer \u001b[38;5;241m=\u001b[39m pretty\u001b[38;5;241m.\u001b[39mRepresentationPrinter(stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewline,\n\u001b[0;32m    766\u001b[0m     max_seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_seq_length,\n\u001b[0;32m    767\u001b[0m     singleton_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingleton_printers,\n\u001b[0;32m    768\u001b[0m     type_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_printers,\n\u001b[0;32m    769\u001b[0m     deferred_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeferred_printers)\n\u001b[1;32m--> 770\u001b[0m \u001b[43mprinter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    771\u001b[0m printer\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[1;32mc:\\Users\\plancha\\purchase-intent\\.venv\\lib\\site-packages\\IPython\\lib\\pretty.py:419\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    408\u001b[0m                         \u001b[38;5;28;01mreturn\u001b[39;00m meth(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[0;32m    409\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    410\u001b[0m                     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\n\u001b[0;32m    411\u001b[0m                     \u001b[38;5;66;03m# check if cls defines __repr__\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m                     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(_safe_getattr(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    418\u001b[0m                 ):\n\u001b[1;32m--> 419\u001b[0m                     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repr_pprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\plancha\\purchase-intent\\.venv\\lib\\site-packages\\IPython\\lib\\pretty.py:794\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[1;34m(obj, p, cycle)\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[0;32m    793\u001b[0m \u001b[38;5;66;03m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[1;32m--> 794\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    795\u001b[0m lines \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgroup():\n",
      "File \u001b[1;32mc:\\Users\\plancha\\purchase-intent\\.venv\\lib\\site-packages\\pyspark\\sql\\connect\\dataframe.py:183\u001b[0m, in \u001b[0;36mDataFrame.__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m     (\n\u001b[0;32m    174\u001b[0m         repl_eager_eval_enabled,\n\u001b[0;32m    175\u001b[0m         repl_eager_eval_max_num_rows,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.sql.repl.eagerEval.truncate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    181\u001b[0m     )\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m repl_eager_eval_enabled \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_show_string\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepl_eager_eval_max_num_rows\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepl_eager_eval_truncate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvertical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame[\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtypes))\n",
      "File \u001b[1;32mc:\\Users\\plancha\\purchase-intent\\.venv\\lib\\site-packages\\pyspark\\sql\\connect\\dataframe.py:872\u001b[0m, in \u001b[0;36mDataFrame._show_string\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m    856\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m    857\u001b[0m             errorClass\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    858\u001b[0m             messageParameters\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    861\u001b[0m             },\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    864\u001b[0m table, _ \u001b[38;5;241m=\u001b[39m \u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mShowString\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchild\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_truncate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvertical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvertical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m--> 872\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m table[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mas_py()\n",
      "File \u001b[1;32mc:\\Users\\plancha\\purchase-intent\\.venv\\lib\\site-packages\\pyspark\\sql\\connect\\dataframe.py:1794\u001b[0m, in \u001b[0;36mDataFrame._to_table\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1792\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_to_table\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpa.Table\u001b[39m\u001b[38;5;124m\"\u001b[39m, Optional[StructType]]:\n\u001b[0;32m   1793\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plan\u001b[38;5;241m.\u001b[39mto_proto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39mclient)\n\u001b[1;32m-> 1794\u001b[0m     table, schema, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execution_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1795\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservations\u001b[49m\n\u001b[0;32m   1796\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1797\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m table \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1798\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (table, schema)\n",
      "File \u001b[1;32mc:\\Users\\plancha\\purchase-intent\\.venv\\lib\\site-packages\\pyspark\\sql\\connect\\client\\core.py:925\u001b[0m, in \u001b[0;36mSparkConnectClient.to_table\u001b[1;34m(self, plan, observations)\u001b[0m\n\u001b[0;32m    923\u001b[0m req \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_plan_request_with_metadata()\n\u001b[0;32m    924\u001b[0m req\u001b[38;5;241m.\u001b[39mplan\u001b[38;5;241m.\u001b[39mCopyFrom(plan)\n\u001b[1;32m--> 925\u001b[0m table, schema, metrics, observed_metrics, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_and_fetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;66;03m# Create a query execution object.\u001b[39;00m\n\u001b[0;32m    928\u001b[0m ei \u001b[38;5;241m=\u001b[39m ExecutionInfo(metrics, observed_metrics)\n",
      "File \u001b[1;32mc:\\Users\\plancha\\purchase-intent\\.venv\\lib\\site-packages\\pyspark\\sql\\connect\\client\\core.py:1560\u001b[0m, in \u001b[0;36mSparkConnectClient._execute_and_fetch\u001b[1;34m(self, req, observations, self_destruct)\u001b[0m\n\u001b[0;32m   1557\u001b[0m properties: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Progress(handlers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_progress_handlers, operation_id\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39moperation_id) \u001b[38;5;28;01mas\u001b[39;00m progress:\n\u001b[1;32m-> 1560\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_and_fetch_as_iterator(\n\u001b[0;32m   1561\u001b[0m         req, observations, progress\u001b[38;5;241m=\u001b[39mprogress\n\u001b[0;32m   1562\u001b[0m     ):\n\u001b[0;32m   1563\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, StructType):\n\u001b[0;32m   1564\u001b[0m             schema \u001b[38;5;241m=\u001b[39m response\n",
      "File \u001b[1;32mc:\\Users\\plancha\\purchase-intent\\.venv\\lib\\site-packages\\pyspark\\sql\\connect\\client\\core.py:1537\u001b[0m, in \u001b[0;36mSparkConnectClient._execute_and_fetch_as_iterator\u001b[1;34m(self, req, observations, progress)\u001b[0m\n\u001b[0;32m   1535\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m kb\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m-> 1537\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\plancha\\purchase-intent\\.venv\\lib\\site-packages\\pyspark\\sql\\connect\\client\\core.py:1811\u001b[0m, in \u001b[0;36mSparkConnectClient._handle_error\u001b[1;34m(self, error)\u001b[0m\n\u001b[0;32m   1809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthread_local\u001b[38;5;241m.\u001b[39minside_error_handling \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1810\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, grpc\u001b[38;5;241m.\u001b[39mRpcError):\n\u001b[1;32m-> 1811\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_rpc_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\plancha\\purchase-intent\\.venv\\lib\\site-packages\\pyspark\\sql\\connect\\client\\core.py:1882\u001b[0m, in \u001b[0;36mSparkConnectClient._handle_rpc_error\u001b[1;34m(self, rpc_error)\u001b[0m\n\u001b[0;32m   1879\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m info\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrorClass\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINVALID_HANDLE.SESSION_CHANGED\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1880\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 1882\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m convert_exception(\n\u001b[0;32m   1883\u001b[0m                 info,\n\u001b[0;32m   1884\u001b[0m                 status\u001b[38;5;241m.\u001b[39mmessage,\n\u001b[0;32m   1885\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetch_enriched_error(info),\n\u001b[0;32m   1886\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_display_server_stack_trace(),\n\u001b[0;32m   1887\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1889\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SparkConnectGrpcException(status\u001b[38;5;241m.\u001b[39mmessage) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mSparkException\u001b[0m: [FAILED_READ_FILE.FILE_NOT_EXIST] Encountered error while reading file file:///opt/spark/data/worker2/online_shoppers_part2.csv. File does not exist. It is possible the underlying files have been updated.\nYou can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved. SQLSTATE: KD001\n\nJVM stacktrace:\norg.apache.spark.SparkException\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.fileNotExistError(QueryExecutionErrors.scala:831)\n\tat org.apache.spark.sql.execution.datasources.v2.FileDataSourceV2$.attachFilePath(FileDataSourceV2.scala:140)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:142)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(:-1)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:263)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:265)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.api.python.PythonRDD$.writeNextElementToStream(PythonRDD.scala:333)\n\tat org.apache.spark.sql.execution.python.BasePythonUDFRunner$$anon$1.writeNextInputToStream(PythonUDFRunner.scala:69)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.writeAdditionalInputToPythonWorker(PythonRunner.scala:844)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.read(PythonRunner.scala:767)\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:244)\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:263)\n\tat java.io.DataInputStream.readInt(DataInputStream.java:381)\n\tat org.apache.spark.sql.execution.python.BasePythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:98)\n\tat org.apache.spark.sql.execution.python.BasePythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:90)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:601)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(:-1)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.lang.Thread.run(Thread.java:840)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1009)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2484)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2505)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2524)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:544)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:497)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:58)\n\tat org.apache.spark.sql.classic.Dataset.collectFromPlan(Dataset.scala:2244)\n\tat org.apache.spark.sql.classic.Dataset.$anonfun$head$1(Dataset.scala:1379)\n\tat org.apache.spark.sql.classic.Dataset.$anonfun$withAction$2(Dataset.scala:2234)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:654)\n\tat org.apache.spark.sql.classic.Dataset.$anonfun$withAction$1(Dataset.scala:2232)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$8(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:272)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$7(SQLExecution.scala:125)\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:186)\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:295)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:124)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:237)\n\tat org.apache.spark.sql.classic.Dataset.withAction(Dataset.scala:2232)\n\tat org.apache.spark.sql.classic.Dataset.head(Dataset.scala:1379)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2810)\n\tat org.apache.spark.sql.classic.Dataset.getRows(Dataset.scala:339)\n\tat org.apache.spark.sql.classic.Dataset.showString(Dataset.scala:375)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.transformShowString(SparkConnectPlanner.scala:307)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.$anonfun$transformRelation$1(SparkConnectPlanner.scala:150)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$usePlanCache$3(SessionHolder.scala:477)\n\tat scala.Option.getOrElse(Option.scala:201)\n\tat org.apache.spark.sql.connect.service.SessionHolder.usePlanCache(SessionHolder.scala:476)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.transformRelation(SparkConnectPlanner.scala:147)\n\tat org.apache.spark.sql.connect.execution.SparkConnectPlanExecution.handlePlan(SparkConnectPlanExecution.scala:74)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.handlePlan(ExecuteThreadRunner.scala:314)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:225)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:196)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:341)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:341)\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:186)\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:340)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:196)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:125)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:347)\nCaused by: java.io.FileNotFoundException: File file:/opt/spark/data/worker2/online_shoppers_part2.csv does not exist\n\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:917)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1238)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:907)\n\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)\n\tat org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:189)\n\tat org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:572)\n\tat org.apache.hadoop.fs.ChecksumFileSystem.lambda$openFileWithOptions$0(ChecksumFileSystem.java:1100)\n\tat org.apache.hadoop.util.LambdaUtils.eval(LambdaUtils.java:52)\n\tat org.apache.hadoop.fs.ChecksumFileSystem.openFileWithOptions(ChecksumFileSystem.java:1098)\n\tat org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder.build(FileSystem.java:4952)\n\tat org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:100)\n\tat org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.$anonfun$_iterator$2(HadoopFileLinesReader.scala:66)\n\tat org.apache.spark.util.SparkErrorUtils.tryInitializeResource(SparkErrorUtils.scala:59)\n\tat org.apache.spark.util.SparkErrorUtils.tryInitializeResource$(SparkErrorUtils.scala:56)\n\tat org.apache.spark.util.Utils$.tryInitializeResource(Utils.scala:99)\n\tat org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.<init>(HadoopFileLinesReader.scala:65)\n\tat org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$.$anonfun$readFile$1(CSVDataSource.scala:105)\n\tat org.apache.spark.TaskContextImpl.createResourceUninterruptibly(TaskContextImpl.scala:332)\n\tat org.apache.spark.util.Utils$.$anonfun$createResourceUninterruptiblyIfInTaskThread$1(Utils.scala:3097)\n\tat scala.Option.map(Option.scala:242)\n\tat org.apache.spark.util.Utils$.createResourceUninterruptiblyIfInTaskThread(Utils.scala:3096)\n\tat org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$.readFile(CSVDataSource.scala:105)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.$anonfun$buildReader$2(CSVFileFormat.scala:147)\n\tat org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.apply(FileFormat.scala:155)\n\tat org.apache.spark.sql.execution.datasources.FileFormat$$anon$1.apply(FileFormat.scala:140)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:230)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:289)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext0(FileScanRDD.scala:131)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:140)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(:-1)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:263)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:265)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.api.python.PythonRDD$.writeNextElementToStream(PythonRDD.scala:333)\n\tat org.apache.spark.sql.execution.python.BasePythonUDFRunner$$anon$1.writeNextInputToStream(PythonUDFRunner.scala:69)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.writeAdditionalInputToPythonWorker(PythonRunner.scala:844)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderInputStream.read(PythonRunner.scala:767)\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:244)\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:263)\n\tat java.io.DataInputStream.readInt(DataInputStream.java:381)\n\tat org.apache.spark.sql.execution.python.BasePythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:98)\n\tat org.apache.spark.sql.execution.python.BasePythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:90)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:532)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:601)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(:-1)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenEvaluatorFactory$WholeStageCodegenPartitionEvaluator$$anon$1.hasNext(WholeStageCodegenEvaluatorFactory.scala:50)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:402)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:901)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:901)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:374)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:338)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:171)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:147)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$5(Executor.scala:647)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:650)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.lang.Thread.run(Thread.java:840)"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Administrative</th><th>Administrative_Duration</th><th>Informational</th><th>Informational_Duration</th><th>ProductRelated</th><th>ProductRelated_Duration</th><th>BounceRates</th><th>ExitRates</th><th>PageValues</th><th>SpecialDay</th><th>Month</th><th>OperatingSystems</th><th>Browser</th><th>Region</th><th>TrafficType</th><th>VisitorType</th><th>Weekend</th><th>Revenue</th><th>Administrative_Duration_Per_Visit</th><th>Informational_Duration_Per_Visit</th><th>ProductRelated_Duration_Per_Visit</th><th>Is_Special_Date</th><th>Month_Number</th></tr>\n",
       "<tr><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>22</td><td>370.3333333</td><td>0.018181818</td><td>0.054545455</td><td>0.0</td><td>0.6</td><td>May</td><td>OS_2</td><td>2</td><td>Region_Other</td><td>TrafficType_Other</td><td>Returning_Visitor</td><td>false</td><td>false</td><td>NULL</td><td>NULL</td><td>16.833334</td><td>true</td><td>5</td></tr>\n",
       "<tr><td>12</td><td>381.5</td><td>1</td><td>22.2</td><td>154</td><td>7835.874629</td><td>0.012549679</td><td>0.022587818</td><td>0.0</td><td>0.0</td><td>Aug</td><td>OS_3</td><td>2</td><td>Region_1</td><td>TrafficType_1_3</td><td>Returning_Visitor</td><td>true</td><td>false</td><td>31.791666</td><td>22.2</td><td>50.8823</td><td>false</td><td>8</td></tr>\n",
       "<tr><td>5</td><td>44.75</td><td>3</td><td>51.5</td><td>107</td><td>3074.852778</td><td>0.015454545</td><td>0.026239965</td><td>0.0</td><td>0.0</td><td>Nov</td><td>OS_2</td><td>2</td><td>Region_Other</td><td>TrafficType_1_3</td><td>Returning_Visitor</td><td>true</td><td>false</td><td>8.95</td><td>17.166666</td><td>28.736942</td><td>false</td><td>11</td></tr>\n",
       "<tr><td>1</td><td>12.0</td><td>0</td><td>0.0</td><td>11</td><td>213.0</td><td>0.05</td><td>0.066666667</td><td>0.0</td><td>0.0</td><td>Nov</td><td>OS_2</td><td>2</td><td>Region_Other</td><td>TrafficType_Other</td><td>Returning_Visitor</td><td>true</td><td>false</td><td>12.0</td><td>NULL</td><td>19.363636</td><td>false</td><td>11</td></tr>\n",
       "<tr><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>1</td><td>0.0</td><td>0.2</td><td>0.2</td><td>0.0</td><td>0.0</td><td>May</td><td>OS_1</td><td>1</td><td>Region_Other</td><td>TrafficType_1_3</td><td>New_Visitor</td><td>false</td><td>false</td><td>NULL</td><td>NULL</td><td>0.0</td><td>false</td><td>5</td></tr>\n",
       "<tr><td>1</td><td>18.0</td><td>1</td><td>16.0</td><td>33</td><td>504.0</td><td>0.006060606</td><td>0.033333333</td><td>0.0</td><td>0.0</td><td>May</td><td>OS_2</td><td>4</td><td>Region_1</td><td>TrafficType_Other</td><td>Returning_Visitor</td><td>false</td><td>false</td><td>18.0</td><td>16.0</td><td>15.272727</td><td>false</td><td>5</td></tr>\n",
       "<tr><td>1</td><td>51.4</td><td>0</td><td>0.0</td><td>7</td><td>562.3</td><td>0.0</td><td>0.0</td><td>36.65735004</td><td>0.0</td><td>Jul</td><td>OS_1</td><td>1</td><td>Region_Other</td><td>TrafficType_1_3</td><td>New_Visitor</td><td>true</td><td>true</td><td>51.4</td><td>NULL</td><td>80.328575</td><td>false</td><td>7</td></tr>\n",
       "<tr><td>2</td><td>46.4</td><td>0</td><td>0.0</td><td>8</td><td>349.0</td><td>0.02</td><td>0.08</td><td>0.0</td><td>0.0</td><td>Aug</td><td>OS_Other</td><td>1</td><td>Region_1</td><td>TrafficType_1_3</td><td>Returning_Visitor</td><td>false</td><td>false</td><td>23.2</td><td>NULL</td><td>43.625</td><td>false</td><td>8</td></tr>\n",
       "<tr><td>4</td><td>54.4</td><td>0</td><td>0.0</td><td>68</td><td>2889.946154</td><td>0.002898551</td><td>0.008789401</td><td>0.0</td><td>0.0</td><td>June</td><td>OS_Other</td><td>1</td><td>Region_Other</td><td>TrafficType_1_3</td><td>Returning_Visitor</td><td>false</td><td>false</td><td>13.6</td><td>NULL</td><td>42.499207</td><td>false</td><td>6</td></tr>\n",
       "<tr><td>3</td><td>335.5</td><td>1</td><td>15.0</td><td>4</td><td>96.0</td><td>0.0</td><td>0.025</td><td>0.0</td><td>0.0</td><td>Nov</td><td>OS_1</td><td>1</td><td>Region_Other</td><td>TrafficType_Other</td><td>Returning_Visitor</td><td>false</td><td>false</td><td>111.833336</td><td>15.0</td><td>24.0</td><td>false</td><td>11</td></tr>\n",
       "<tr><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>2</td><td>36.5</td><td>0.0</td><td>0.033333333</td><td>0.0</td><td>0.0</td><td>Mar</td><td>OS_3</td><td>2</td><td>Region_1</td><td>TrafficType_1_3</td><td>Returning_Visitor</td><td>false</td><td>false</td><td>NULL</td><td>NULL</td><td>18.25</td><td>false</td><td>3</td></tr>\n",
       "<tr><td>8</td><td>160.5</td><td>2</td><td>1467.0</td><td>26</td><td>721.0</td><td>0.0</td><td>0.031029186</td><td>0.0</td><td>0.0</td><td>Mar</td><td>OS_2</td><td>2</td><td>Region_1</td><td>TrafficType_1_3</td><td>Returning_Visitor</td><td>false</td><td>false</td><td>20.0625</td><td>733.5</td><td>27.73077</td><td>false</td><td>3</td></tr>\n",
       "<tr><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>7</td><td>87.5</td><td>0.028571429</td><td>0.085714286</td><td>0.0</td><td>0.6</td><td>May</td><td>OS_2</td><td>2</td><td>Region_Other</td><td>TrafficType_1_3</td><td>Returning_Visitor</td><td>false</td><td>false</td><td>NULL</td><td>NULL</td><td>12.5</td><td>true</td><td>5</td></tr>\n",
       "<tr><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>1</td><td>0.0</td><td>0.2</td><td>0.2</td><td>0.0</td><td>0.0</td><td>Feb</td><td>OS_1</td><td>1</td><td>Region_Other</td><td>TrafficType_1_3</td><td>Returning_Visitor</td><td>false</td><td>false</td><td>NULL</td><td>NULL</td><td>0.0</td><td>false</td><td>2</td></tr>\n",
       "<tr><td>16</td><td>381.6731217</td><td>3</td><td>199.4</td><td>86</td><td>1618.40328</td><td>0.015067698</td><td>0.022043153</td><td>3.885233567</td><td>0.0</td><td>Jul</td><td>OS_3</td><td>2</td><td>Region_Other</td><td>TrafficType_Other</td><td>Returning_Visitor</td><td>false</td><td>true</td><td>23.85457</td><td>66.46667</td><td>18.818644</td><td>false</td><td>7</td></tr>\n",
       "<tr><td>4</td><td>26.0</td><td>0</td><td>0.0</td><td>18</td><td>727.6190476</td><td>0.0</td><td>0.013333333</td><td>0.0</td><td>0.0</td><td>May</td><td>OS_2</td><td>2</td><td>Region_Other</td><td>TrafficType_1_3</td><td>New_Visitor</td><td>true</td><td>false</td><td>6.5</td><td>NULL</td><td>40.42328</td><td>false</td><td>5</td></tr>\n",
       "<tr><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>2</td><td>54.5</td><td>0.1</td><td>0.12</td><td>0.0</td><td>0.0</td><td>May</td><td>OS_3</td><td>2</td><td>Region_1</td><td>TrafficType_Other</td><td>Returning_Visitor</td><td>false</td><td>false</td><td>NULL</td><td>NULL</td><td>27.25</td><td>false</td><td>5</td></tr>\n",
       "<tr><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>65</td><td>6053.466667</td><td>0.005208333</td><td>0.026197917</td><td>0.0</td><td>0.0</td><td>Sep</td><td>OS_2</td><td>4</td><td>Region_Other</td><td>TrafficType_1_3</td><td>Returning_Visitor</td><td>false</td><td>false</td><td>NULL</td><td>NULL</td><td>93.13026</td><td>false</td><td>9</td></tr>\n",
       "<tr><td>11</td><td>196.15</td><td>0</td><td>0.0</td><td>141</td><td>2623.580864</td><td>0.0</td><td>0.004244028</td><td>12.50786523</td><td>0.0</td><td>Nov</td><td>OS_2</td><td>2</td><td>Region_Other</td><td>TrafficType_1_3</td><td>Returning_Visitor</td><td>false</td><td>false</td><td>17.831818</td><td>NULL</td><td>18.606956</td><td>false</td><td>11</td></tr>\n",
       "<tr><td>5</td><td>105.5</td><td>0</td><td>0.0</td><td>16</td><td>733.252381</td><td>0.0</td><td>0.006862745</td><td>0.0</td><td>0.0</td><td>May</td><td>OS_3</td><td>2</td><td>Region_1</td><td>TrafficType_Other</td><td>New_Visitor</td><td>false</td><td>false</td><td>21.1</td><td>NULL</td><td>45.828274</td><td>false</td><td>5</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import FloatType, IntegerType, BooleanType, StringType\n",
    "\n",
    "@udf(FloatType())\n",
    "def ratio_duration_per_visit(visitc, duration):\n",
    "  return 0 if visitc == 0 else duration / visitc\n",
    "  \n",
    "@udf(BooleanType())\n",
    "def is_special_date(special_day):\n",
    "  return special_day > 0\n",
    "\n",
    "@udf(StringType())\n",
    "def operating_system_label(os):\n",
    "  match os:\n",
    "    case 1:\n",
    "      return 'OS_1'\n",
    "    case 2:\n",
    "      return 'OS_2'\n",
    "    case 3:\n",
    "      return 'OS_3'\n",
    "    case _:\n",
    "      return 'OS_Other'\n",
    "    \n",
    "@udf(StringType())\n",
    "def region_label(region):\n",
    "  return 'Region_1' if region == 1 else 'Region_Other'\n",
    "\n",
    "@udf(StringType())\n",
    "def traffic_type_label(traffic_type):\n",
    "  return 'TrafficType_1_3' if 1 <= traffic_type <= 3 else 'TrafficType_Other'\n",
    "\n",
    "@udf(IntegerType())\n",
    "def month_number(month):\n",
    "  month_mapping = {\n",
    "    'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'June': 6,\n",
    "    'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12\n",
    "  }\n",
    "  return month_mapping[month]\n",
    "sessions_data_fe = sessions_data.withColumns({\n",
    "  \"Administrative_Duration_Per_Visit\": ratio_duration_per_visit(\n",
    "    col(\"Administrative\"), col(\"Administrative_Duration\")\n",
    "  ),\n",
    "  \"Informational_Duration_Per_Visit\": ratio_duration_per_visit(\n",
    "    col(\"Informational\"), col(\"Informational_Duration\")\n",
    "  ),\n",
    "  \"ProductRelated_Duration_Per_Visit\": ratio_duration_per_visit(\n",
    "    col(\"ProductRelated\"), col(\"ProductRelated_Duration\")\n",
    "  ),\n",
    "  \"Is_Special_Date\": is_special_date(col(\"SpecialDay\")),\n",
    "  \"OperatingSystems\": operating_system_label(col(\"OperatingSystems\")),\n",
    "  \"Region\": region_label(col(\"Region\")),\n",
    "  \"TrafficType\": traffic_type_label(col(\"TrafficType\")),\n",
    "  \"Month_Number\": month_number(col(\"Month\"))\n",
    "})\n",
    "sessions_data_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4424b6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Revenue</th><th>Administrative_Duration_Per_Visit</th><th>Informational_Duration_Per_Visit</th><th>ProductRelated_Duration_Per_Visit</th><th>BounceRates</th><th>ExitRates</th><th>PageValues</th><th>Is_Special_Date</th><th>Month_Number</th><th>OperatingSystems</th><th>Region</th><th>TrafficType</th><th>Weekend</th></tr>\n",
       "<tr><td>false</td><td>NULL</td><td>NULL</td><td>16.833334</td><td>0.018181818</td><td>0.054545455</td><td>0.0</td><td>true</td><td>5</td><td>OS_2</td><td>Region_Other</td><td>TrafficType_Other</td><td>false</td></tr>\n",
       "<tr><td>false</td><td>31.791666</td><td>22.2</td><td>50.8823</td><td>0.012549679</td><td>0.022587818</td><td>0.0</td><td>false</td><td>8</td><td>OS_3</td><td>Region_1</td><td>TrafficType_1_3</td><td>true</td></tr>\n",
       "<tr><td>false</td><td>8.95</td><td>17.166666</td><td>28.736942</td><td>0.015454545</td><td>0.026239965</td><td>0.0</td><td>false</td><td>11</td><td>OS_2</td><td>Region_Other</td><td>TrafficType_1_3</td><td>true</td></tr>\n",
       "<tr><td>false</td><td>12.0</td><td>NULL</td><td>19.363636</td><td>0.05</td><td>0.066666667</td><td>0.0</td><td>false</td><td>11</td><td>OS_2</td><td>Region_Other</td><td>TrafficType_Other</td><td>true</td></tr>\n",
       "<tr><td>false</td><td>NULL</td><td>NULL</td><td>0.0</td><td>0.2</td><td>0.2</td><td>0.0</td><td>false</td><td>5</td><td>OS_1</td><td>Region_Other</td><td>TrafficType_1_3</td><td>false</td></tr>\n",
       "<tr><td>false</td><td>18.0</td><td>16.0</td><td>15.272727</td><td>0.006060606</td><td>0.033333333</td><td>0.0</td><td>false</td><td>5</td><td>OS_2</td><td>Region_1</td><td>TrafficType_Other</td><td>false</td></tr>\n",
       "<tr><td>true</td><td>51.4</td><td>NULL</td><td>80.328575</td><td>0.0</td><td>0.0</td><td>36.65735004</td><td>false</td><td>7</td><td>OS_1</td><td>Region_Other</td><td>TrafficType_1_3</td><td>true</td></tr>\n",
       "<tr><td>false</td><td>23.2</td><td>NULL</td><td>43.625</td><td>0.02</td><td>0.08</td><td>0.0</td><td>false</td><td>8</td><td>OS_Other</td><td>Region_1</td><td>TrafficType_1_3</td><td>false</td></tr>\n",
       "<tr><td>false</td><td>13.6</td><td>NULL</td><td>42.499207</td><td>0.002898551</td><td>0.008789401</td><td>0.0</td><td>false</td><td>6</td><td>OS_Other</td><td>Region_Other</td><td>TrafficType_1_3</td><td>false</td></tr>\n",
       "<tr><td>false</td><td>111.833336</td><td>15.0</td><td>24.0</td><td>0.0</td><td>0.025</td><td>0.0</td><td>false</td><td>11</td><td>OS_1</td><td>Region_Other</td><td>TrafficType_Other</td><td>false</td></tr>\n",
       "<tr><td>false</td><td>NULL</td><td>NULL</td><td>18.25</td><td>0.0</td><td>0.033333333</td><td>0.0</td><td>false</td><td>3</td><td>OS_3</td><td>Region_1</td><td>TrafficType_1_3</td><td>false</td></tr>\n",
       "<tr><td>false</td><td>20.0625</td><td>733.5</td><td>27.73077</td><td>0.0</td><td>0.031029186</td><td>0.0</td><td>false</td><td>3</td><td>OS_2</td><td>Region_1</td><td>TrafficType_1_3</td><td>false</td></tr>\n",
       "<tr><td>false</td><td>NULL</td><td>NULL</td><td>12.5</td><td>0.028571429</td><td>0.085714286</td><td>0.0</td><td>true</td><td>5</td><td>OS_2</td><td>Region_Other</td><td>TrafficType_1_3</td><td>false</td></tr>\n",
       "<tr><td>false</td><td>NULL</td><td>NULL</td><td>0.0</td><td>0.2</td><td>0.2</td><td>0.0</td><td>false</td><td>2</td><td>OS_1</td><td>Region_Other</td><td>TrafficType_1_3</td><td>false</td></tr>\n",
       "<tr><td>true</td><td>23.85457</td><td>66.46667</td><td>18.818644</td><td>0.015067698</td><td>0.022043153</td><td>3.885233567</td><td>false</td><td>7</td><td>OS_3</td><td>Region_Other</td><td>TrafficType_Other</td><td>false</td></tr>\n",
       "<tr><td>false</td><td>6.5</td><td>NULL</td><td>40.42328</td><td>0.0</td><td>0.013333333</td><td>0.0</td><td>false</td><td>5</td><td>OS_2</td><td>Region_Other</td><td>TrafficType_1_3</td><td>true</td></tr>\n",
       "<tr><td>false</td><td>NULL</td><td>NULL</td><td>27.25</td><td>0.1</td><td>0.12</td><td>0.0</td><td>false</td><td>5</td><td>OS_3</td><td>Region_1</td><td>TrafficType_Other</td><td>false</td></tr>\n",
       "<tr><td>false</td><td>NULL</td><td>NULL</td><td>93.13026</td><td>0.005208333</td><td>0.026197917</td><td>0.0</td><td>false</td><td>9</td><td>OS_2</td><td>Region_Other</td><td>TrafficType_1_3</td><td>false</td></tr>\n",
       "<tr><td>false</td><td>17.831818</td><td>NULL</td><td>18.606956</td><td>0.0</td><td>0.004244028</td><td>12.50786523</td><td>false</td><td>11</td><td>OS_2</td><td>Region_Other</td><td>TrafficType_1_3</td><td>false</td></tr>\n",
       "<tr><td>false</td><td>21.1</td><td>NULL</td><td>45.828274</td><td>0.0</td><td>0.006862745</td><td>0.0</td><td>false</td><td>5</td><td>OS_3</td><td>Region_1</td><td>TrafficType_Other</td><td>false</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+-------+---------------------------------+--------------------------------+---------------------------------+-----------+-----------+-----------+---------------+------------+----------------+------------+-----------------+-------+\n",
       "|Revenue|Administrative_Duration_Per_Visit|Informational_Duration_Per_Visit|ProductRelated_Duration_Per_Visit|BounceRates|  ExitRates| PageValues|Is_Special_Date|Month_Number|OperatingSystems|      Region|      TrafficType|Weekend|\n",
       "+-------+---------------------------------+--------------------------------+---------------------------------+-----------+-----------+-----------+---------------+------------+----------------+------------+-----------------+-------+\n",
       "|  false|                             NULL|                            NULL|                        16.833334|0.018181818|0.054545455|        0.0|           true|           5|            OS_2|Region_Other|TrafficType_Other|  false|\n",
       "|  false|                        31.791666|                            22.2|                          50.8823|0.012549679|0.022587818|        0.0|          false|           8|            OS_3|    Region_1|  TrafficType_1_3|   true|\n",
       "|  false|                             8.95|                       17.166666|                        28.736942|0.015454545|0.026239965|        0.0|          false|          11|            OS_2|Region_Other|  TrafficType_1_3|   true|\n",
       "|  false|                             12.0|                            NULL|                        19.363636|       0.05|0.066666667|        0.0|          false|          11|            OS_2|Region_Other|TrafficType_Other|   true|\n",
       "|  false|                             NULL|                            NULL|                              0.0|        0.2|        0.2|        0.0|          false|           5|            OS_1|Region_Other|  TrafficType_1_3|  false|\n",
       "|  false|                             18.0|                            16.0|                        15.272727|0.006060606|0.033333333|        0.0|          false|           5|            OS_2|    Region_1|TrafficType_Other|  false|\n",
       "|   true|                             51.4|                            NULL|                        80.328575|        0.0|        0.0|36.65735004|          false|           7|            OS_1|Region_Other|  TrafficType_1_3|   true|\n",
       "|  false|                             23.2|                            NULL|                           43.625|       0.02|       0.08|        0.0|          false|           8|        OS_Other|    Region_1|  TrafficType_1_3|  false|\n",
       "|  false|                             13.6|                            NULL|                        42.499207|0.002898551|0.008789401|        0.0|          false|           6|        OS_Other|Region_Other|  TrafficType_1_3|  false|\n",
       "|  false|                       111.833336|                            15.0|                             24.0|        0.0|      0.025|        0.0|          false|          11|            OS_1|Region_Other|TrafficType_Other|  false|\n",
       "|  false|                             NULL|                            NULL|                            18.25|        0.0|0.033333333|        0.0|          false|           3|            OS_3|    Region_1|  TrafficType_1_3|  false|\n",
       "|  false|                          20.0625|                           733.5|                         27.73077|        0.0|0.031029186|        0.0|          false|           3|            OS_2|    Region_1|  TrafficType_1_3|  false|\n",
       "|  false|                             NULL|                            NULL|                             12.5|0.028571429|0.085714286|        0.0|           true|           5|            OS_2|Region_Other|  TrafficType_1_3|  false|\n",
       "|  false|                             NULL|                            NULL|                              0.0|        0.2|        0.2|        0.0|          false|           2|            OS_1|Region_Other|  TrafficType_1_3|  false|\n",
       "|   true|                         23.85457|                        66.46667|                        18.818644|0.015067698|0.022043153|3.885233567|          false|           7|            OS_3|Region_Other|TrafficType_Other|  false|\n",
       "|  false|                              6.5|                            NULL|                         40.42328|        0.0|0.013333333|        0.0|          false|           5|            OS_2|Region_Other|  TrafficType_1_3|   true|\n",
       "|  false|                             NULL|                            NULL|                            27.25|        0.1|       0.12|        0.0|          false|           5|            OS_3|    Region_1|TrafficType_Other|  false|\n",
       "|  false|                             NULL|                            NULL|                         93.13026|0.005208333|0.026197917|        0.0|          false|           9|            OS_2|Region_Other|  TrafficType_1_3|  false|\n",
       "|  false|                        17.831818|                            NULL|                        18.606956|        0.0|0.004244028|12.50786523|          false|          11|            OS_2|Region_Other|  TrafficType_1_3|  false|\n",
       "|  false|                             21.1|                            NULL|                        45.828274|        0.0|0.006862745|        0.0|          false|           5|            OS_3|    Region_1|TrafficType_Other|  false|\n",
       "+-------+---------------------------------+--------------------------------+---------------------------------+-----------+-----------+-----------+---------------+------------+----------------+------------+-----------------+-------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only important features\n",
    "sessions_data_fee = sessions_data_fe.select([\n",
    "  \"Revenue\",\n",
    "  \"Administrative_Duration_Per_Visit\",\n",
    "  \"Informational_Duration_Per_Visit\",\n",
    "  \"ProductRelated_Duration_Per_Visit\",\n",
    "  \"BounceRates\",\n",
    "  \"ExitRates\",\n",
    "  \"PageValues\",\n",
    "  \"Is_Special_Date\",\n",
    "  \"Month_Number\",\n",
    "  \"OperatingSystems\",\n",
    "  \"Region\",\n",
    "  \"TrafficType\",\n",
    "  \"Weekend\"\n",
    "])\n",
    "sessions_data_fee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840104d3",
   "metadata": {},
   "source": [
    "## Handle 0 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0a6163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum as spark_sum, col, coalesce, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58dc086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where at least one column is null\n",
    "\n",
    "def print_null_rows(df):\n",
    "    rows_with_nulls = df.filter(\n",
    "        \" OR \".join([f\"`{c}` IS NULL\" for c in df.columns]) # if any row is null in any column\n",
    "    )\n",
    "\n",
    "    print(f\"Total rows with null values: {rows_with_nulls.count()}\")\n",
    "    rows_with_nulls.show(truncate=False)\n",
    "\n",
    "\n",
    "def check_null_values(df):\n",
    "    \"\"\"Check and display null value counts per column\"\"\"\n",
    "    # Get null counts per column\n",
    "    null_counts = df.select([\n",
    "        spark_sum(col(c).isNull().cast(\"int\")).alias(c) \n",
    "        for c in df.columns\n",
    "    ])\n",
    "    \n",
    "    print(\"Null value counts per column:\")\n",
    "    null_counts.show(vertical=True)\n",
    "    \n",
    "    # Show only columns with nulls\n",
    "    row = null_counts.collect()[0]\n",
    "    print(\"\\nColumns with null values:\")\n",
    "    has_nulls = False\n",
    "    for col_name in df.columns:\n",
    "        count = row[col_name]\n",
    "        if count > 0:\n",
    "            print(f\"  {col_name}: {count}\")\n",
    "            has_nulls = True\n",
    "    \n",
    "    if not has_nulls:\n",
    "        print(\"  No null values found\")\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bfed326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null value counts per column:\n",
      "-RECORD 0---------------------------------\n",
      " Revenue                           | 0    \n",
      " Administrative_Duration_Per_Visit | 5768 \n",
      " Informational_Duration_Per_Visit  | 9699 \n",
      " ProductRelated_Duration_Per_Visit | 38   \n",
      " BounceRates                       | 0    \n",
      " ExitRates                         | 0    \n",
      " PageValues                        | 0    \n",
      " Is_Special_Date                   | 0    \n",
      " Month_Number                      | 0    \n",
      " OperatingSystems                  | 0    \n",
      " Region                            | 0    \n",
      " TrafficType                       | 0    \n",
      " Weekend                           | 0    \n",
      "\n",
      "\n",
      "Columns with null values:\n",
      "  Administrative_Duration_Per_Visit: 5768\n",
      "  Informational_Duration_Per_Visit: 9699\n",
      "  ProductRelated_Duration_Per_Visit: 38\n",
      "Total rows with null values: 10163\n",
      "+-------+---------------------------------+--------------------------------+---------------------------------+-----------+-----------+-----------+---------------+------------+----------------+------------+-----------------+-------+\n",
      "|Revenue|Administrative_Duration_Per_Visit|Informational_Duration_Per_Visit|ProductRelated_Duration_Per_Visit|BounceRates|ExitRates  |PageValues |Is_Special_Date|Month_Number|OperatingSystems|Region      |TrafficType      |Weekend|\n",
      "+-------+---------------------------------+--------------------------------+---------------------------------+-----------+-----------+-----------+---------------+------------+----------------+------------+-----------------+-------+\n",
      "|false  |NULL                             |NULL                            |16.833334                        |0.018181818|0.054545455|0.0        |true           |5           |OS_2            |Region_Other|TrafficType_Other|false  |\n",
      "|false  |12.0                             |NULL                            |19.363636                        |0.05       |0.066666667|0.0        |false          |11          |OS_2            |Region_Other|TrafficType_Other|true   |\n",
      "|false  |NULL                             |NULL                            |0.0                              |0.2        |0.2        |0.0        |false          |5           |OS_1            |Region_Other|TrafficType_1_3  |false  |\n",
      "|true   |51.4                             |NULL                            |80.328575                        |0.0        |0.0        |36.65735004|false          |7           |OS_1            |Region_Other|TrafficType_1_3  |true   |\n",
      "|false  |23.2                             |NULL                            |43.625                           |0.02       |0.08       |0.0        |false          |8           |OS_Other        |Region_1    |TrafficType_1_3  |false  |\n",
      "|false  |13.6                             |NULL                            |42.499207                        |0.002898551|0.008789401|0.0        |false          |6           |OS_Other        |Region_Other|TrafficType_1_3  |false  |\n",
      "|false  |NULL                             |NULL                            |18.25                            |0.0        |0.033333333|0.0        |false          |3           |OS_3            |Region_1    |TrafficType_1_3  |false  |\n",
      "|false  |NULL                             |NULL                            |12.5                             |0.028571429|0.085714286|0.0        |true           |5           |OS_2            |Region_Other|TrafficType_1_3  |false  |\n",
      "|false  |NULL                             |NULL                            |0.0                              |0.2        |0.2        |0.0        |false          |2           |OS_1            |Region_Other|TrafficType_1_3  |false  |\n",
      "|false  |6.5                              |NULL                            |40.42328                         |0.0        |0.013333333|0.0        |false          |5           |OS_2            |Region_Other|TrafficType_1_3  |true   |\n",
      "|false  |NULL                             |NULL                            |27.25                            |0.1        |0.12       |0.0        |false          |5           |OS_3            |Region_1    |TrafficType_Other|false  |\n",
      "|false  |NULL                             |NULL                            |93.13026                         |0.005208333|0.026197917|0.0        |false          |9           |OS_2            |Region_Other|TrafficType_1_3  |false  |\n",
      "|false  |17.831818                        |NULL                            |18.606956                        |0.0        |0.004244028|12.50786523|false          |11          |OS_2            |Region_Other|TrafficType_1_3  |false  |\n",
      "|false  |21.1                             |NULL                            |45.828274                        |0.0        |0.006862745|0.0        |false          |5           |OS_3            |Region_1    |TrafficType_Other|false  |\n",
      "|false  |21.083334                        |NULL                            |28.854902                        |0.0        |0.01175    |23.5144    |false          |5           |OS_2            |Region_Other|TrafficType_1_3  |false  |\n",
      "|true   |NULL                             |NULL                            |39.583332                        |0.0        |0.014285714|92.9394993 |false          |11          |OS_1            |Region_Other|TrafficType_Other|true   |\n",
      "|false  |NULL                             |NULL                            |28.636364                        |0.0        |0.036363636|0.0        |false          |12          |OS_3            |Region_Other|TrafficType_1_3  |true   |\n",
      "|true   |23.716667                        |NULL                            |36.91526                         |0.008333333|0.042708333|18.08644865|false          |7           |OS_3            |Region_Other|TrafficType_Other|false  |\n",
      "|false  |NULL                             |NULL                            |29.475                           |0.0        |0.03       |0.0        |false          |12          |OS_1            |Region_Other|TrafficType_Other|false  |\n",
      "|false  |13.0                             |NULL                            |2.0                              |0.0        |0.04       |0.0        |false          |3           |OS_2            |Region_1    |TrafficType_1_3  |false  |\n",
      "+-------+---------------------------------+--------------------------------+---------------------------------+-----------+-----------+-----------+---------------+------------+----------------+------------+-----------------+-------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "check_null_values(sessions_data_fee)\n",
    "print_null_rows(sessions_data_fee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7963cc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Null rows should be \n",
    "sessions_data_fee = sessions_data_fee.select([\n",
    "    coalesce(col(c), lit(0)).alias(c) if c in ['Administrative_Duration_Per_Visit', 'Informational_Duration_Per_Visit', 'ProductRelated_Duration_Per_Visit'] else col(c)\n",
    "    for c in sessions_data_fee.columns\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3f8a805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows with null values: 0\n",
      "+-------+---------------------------------+--------------------------------+---------------------------------+-----------+---------+----------+---------------+------------+----------------+------+-----------+-------+\n",
      "|Revenue|Administrative_Duration_Per_Visit|Informational_Duration_Per_Visit|ProductRelated_Duration_Per_Visit|BounceRates|ExitRates|PageValues|Is_Special_Date|Month_Number|OperatingSystems|Region|TrafficType|Weekend|\n",
      "+-------+---------------------------------+--------------------------------+---------------------------------+-----------+---------+----------+---------------+------------+----------------+------+-----------+-------+\n",
      "+-------+---------------------------------+--------------------------------+---------------------------------+-----------+---------+----------+---------------+------------+----------------+------+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_null_rows(sessions_data_fee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f75d42da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Revenue</th><th>Administrative_Duration_Per_Visit</th><th>Informational_Duration_Per_Visit</th><th>ProductRelated_Duration_Per_Visit</th><th>BounceRates</th><th>ExitRates</th><th>PageValues</th><th>Is_Special_Date</th><th>Month_Number</th><th>OperatingSystems</th><th>Region</th><th>TrafficType</th><th>Weekend</th></tr>\n",
       "<tr><td>false</td><td>0.0</td><td>0.0</td><td>16.833334</td><td>0.018181818</td><td>0.054545455</td><td>0.0</td><td>true</td><td>5</td><td>OS_2</td><td>Region_Other</td><td>TrafficType_Other</td><td>false</td></tr>\n",
       "<tr><td>false</td><td>31.791666</td><td>22.2</td><td>50.8823</td><td>0.012549679</td><td>0.022587818</td><td>0.0</td><td>false</td><td>8</td><td>OS_3</td><td>Region_1</td><td>TrafficType_1_3</td><td>true</td></tr>\n",
       "<tr><td>false</td><td>8.95</td><td>17.166666</td><td>28.736942</td><td>0.015454545</td><td>0.026239965</td><td>0.0</td><td>false</td><td>11</td><td>OS_2</td><td>Region_Other</td><td>TrafficType_1_3</td><td>true</td></tr>\n",
       "<tr><td>false</td><td>12.0</td><td>0.0</td><td>19.363636</td><td>0.05</td><td>0.066666667</td><td>0.0</td><td>false</td><td>11</td><td>OS_2</td><td>Region_Other</td><td>TrafficType_Other</td><td>true</td></tr>\n",
       "<tr><td>false</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.2</td><td>0.2</td><td>0.0</td><td>false</td><td>5</td><td>OS_1</td><td>Region_Other</td><td>TrafficType_1_3</td><td>false</td></tr>\n",
       "<tr><td>false</td><td>18.0</td><td>16.0</td><td>15.272727</td><td>0.006060606</td><td>0.033333333</td><td>0.0</td><td>false</td><td>5</td><td>OS_2</td><td>Region_1</td><td>TrafficType_Other</td><td>false</td></tr>\n",
       "<tr><td>true</td><td>51.4</td><td>0.0</td><td>80.328575</td><td>0.0</td><td>0.0</td><td>36.65735004</td><td>false</td><td>7</td><td>OS_1</td><td>Region_Other</td><td>TrafficType_1_3</td><td>true</td></tr>\n",
       "<tr><td>false</td><td>23.2</td><td>0.0</td><td>43.625</td><td>0.02</td><td>0.08</td><td>0.0</td><td>false</td><td>8</td><td>OS_Other</td><td>Region_1</td><td>TrafficType_1_3</td><td>false</td></tr>\n",
       "<tr><td>false</td><td>13.6</td><td>0.0</td><td>42.499207</td><td>0.002898551</td><td>0.008789401</td><td>0.0</td><td>false</td><td>6</td><td>OS_Other</td><td>Region_Other</td><td>TrafficType_1_3</td><td>false</td></tr>\n",
       "<tr><td>false</td><td>111.833336</td><td>15.0</td><td>24.0</td><td>0.0</td><td>0.025</td><td>0.0</td><td>false</td><td>11</td><td>OS_1</td><td>Region_Other</td><td>TrafficType_Other</td><td>false</td></tr>\n",
       "<tr><td>false</td><td>0.0</td><td>0.0</td><td>18.25</td><td>0.0</td><td>0.033333333</td><td>0.0</td><td>false</td><td>3</td><td>OS_3</td><td>Region_1</td><td>TrafficType_1_3</td><td>false</td></tr>\n",
       "<tr><td>false</td><td>20.0625</td><td>733.5</td><td>27.73077</td><td>0.0</td><td>0.031029186</td><td>0.0</td><td>false</td><td>3</td><td>OS_2</td><td>Region_1</td><td>TrafficType_1_3</td><td>false</td></tr>\n",
       "<tr><td>false</td><td>0.0</td><td>0.0</td><td>12.5</td><td>0.028571429</td><td>0.085714286</td><td>0.0</td><td>true</td><td>5</td><td>OS_2</td><td>Region_Other</td><td>TrafficType_1_3</td><td>false</td></tr>\n",
       "<tr><td>false</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.2</td><td>0.2</td><td>0.0</td><td>false</td><td>2</td><td>OS_1</td><td>Region_Other</td><td>TrafficType_1_3</td><td>false</td></tr>\n",
       "<tr><td>true</td><td>23.85457</td><td>66.46667</td><td>18.818644</td><td>0.015067698</td><td>0.022043153</td><td>3.885233567</td><td>false</td><td>7</td><td>OS_3</td><td>Region_Other</td><td>TrafficType_Other</td><td>false</td></tr>\n",
       "<tr><td>false</td><td>6.5</td><td>0.0</td><td>40.42328</td><td>0.0</td><td>0.013333333</td><td>0.0</td><td>false</td><td>5</td><td>OS_2</td><td>Region_Other</td><td>TrafficType_1_3</td><td>true</td></tr>\n",
       "<tr><td>false</td><td>0.0</td><td>0.0</td><td>27.25</td><td>0.1</td><td>0.12</td><td>0.0</td><td>false</td><td>5</td><td>OS_3</td><td>Region_1</td><td>TrafficType_Other</td><td>false</td></tr>\n",
       "<tr><td>false</td><td>0.0</td><td>0.0</td><td>93.13026</td><td>0.005208333</td><td>0.026197917</td><td>0.0</td><td>false</td><td>9</td><td>OS_2</td><td>Region_Other</td><td>TrafficType_1_3</td><td>false</td></tr>\n",
       "<tr><td>false</td><td>17.831818</td><td>0.0</td><td>18.606956</td><td>0.0</td><td>0.004244028</td><td>12.50786523</td><td>false</td><td>11</td><td>OS_2</td><td>Region_Other</td><td>TrafficType_1_3</td><td>false</td></tr>\n",
       "<tr><td>false</td><td>21.1</td><td>0.0</td><td>45.828274</td><td>0.0</td><td>0.006862745</td><td>0.0</td><td>false</td><td>5</td><td>OS_3</td><td>Region_1</td><td>TrafficType_Other</td><td>false</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "DataFrame[Revenue: boolean, Administrative_Duration_Per_Visit: float, Informational_Duration_Per_Visit: float, ProductRelated_Duration_Per_Visit: float, BounceRates: double, ExitRates: double, PageValues: double, Is_Special_Date: boolean, Month_Number: int, OperatingSystems: string, Region: string, TrafficType: string, Weekend: boolean]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions_data_fee"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "purchase-intent (3.10.17)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
